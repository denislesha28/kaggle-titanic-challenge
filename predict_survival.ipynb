{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-25T22:00:59.108932800Z",
     "start_time": "2024-02-25T22:00:58.124259800Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb \n",
    "from xgboost import XGBClassifier\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "             Survived  Pclass  \\\nPassengerId                     \n1                   0       3   \n2                   1       1   \n3                   1       3   \n4                   1       1   \n5                   0       3   \n...               ...     ...   \n887                 0       2   \n888                 1       1   \n889                 0       3   \n890                 1       1   \n891                 0       3   \n\n                                                          Name   Age  SibSp  \\\nPassengerId                                                                   \n1                                      Braund, Mr. Owen Harris  22.0      1   \n2            Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0      1   \n3                                       Heikkinen, Miss. Laina  26.0      0   \n4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0      1   \n5                                     Allen, Mr. William Henry  35.0      0   \n...                                                        ...   ...    ...   \n887                                      Montvila, Rev. Juozas  27.0      0   \n888                               Graham, Miss. Margaret Edith  19.0      0   \n889                   Johnston, Miss. Catherine Helen \"Carrie\"   NaN      1   \n890                                      Behr, Mr. Karl Howell  26.0      0   \n891                                        Dooley, Mr. Patrick  32.0      0   \n\n             Parch            Ticket     Fare Cabin Embarked  \nPassengerId                                                   \n1                0         A/5 21171   7.2500   NaN        S  \n2                0          PC 17599  71.2833   C85        C  \n3                0  STON/O2. 3101282   7.9250   NaN        S  \n4                0            113803  53.1000  C123        S  \n5                0            373450   8.0500   NaN        S  \n...            ...               ...      ...   ...      ...  \n887              0            211536  13.0000   NaN        S  \n888              0            112053  30.0000   B42        S  \n889              2        W./C. 6607  23.4500   NaN        S  \n890              0            111369  30.0000  C148        C  \n891              0            370376   7.7500   NaN        Q  \n\n[891 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>0</td>\n      <td>2</td>\n      <td>Montvila, Rev. Juozas</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>211536</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Graham, Miss. Margaret Edith</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112053</td>\n      <td>30.0000</td>\n      <td>B42</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>W./C. 6607</td>\n      <td>23.4500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Behr, Mr. Karl Howell</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111369</td>\n      <td>30.0000</td>\n      <td>C148</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>891</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Dooley, Mr. Patrick</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>370376</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows Ã— 10 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\", index_col=\"PassengerId\")\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T22:00:59.137272300Z",
     "start_time": "2024-02-25T22:00:59.109933100Z"
    }
   },
   "id": "7437cf88e2628702",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Survived             Int64\nPclass               Int64\nName        string[python]\nAge                Float64\nSibSp                Int64\nParch                Int64\nTicket      string[python]\nFare               Float64\nCabin       string[python]\nEmbarked          category\ndtype: object"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.convert_dtypes()\n",
    "df[\"Embarked\"] = df[\"Embarked\"].astype(\"category\")\n",
    "df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T22:00:59.144425700Z",
     "start_time": "2024-02-25T22:00:59.130272500Z"
    }
   },
   "id": "bc7c0dd7b79336e6",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Cabin', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df.drop(\"Survived\", axis=1), df[\"Survived\"], test_size=0.3, random_state=77)\n",
    "print(df.columns[df.isna().any(axis=0)].tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T22:00:59.187897500Z",
     "start_time": "2024-02-25T22:00:59.144425700Z"
    }
   },
   "id": "311deef3a7079778",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Pre-Processing after splitting the data to prevent data - leakage"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81f55df3da10ac26"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Data Imputation for the Age column\n",
    "data = [X_train, X_test]\n",
    "for dataset in data:\n",
    "    mean = X_train[\"Age\"].mean()\n",
    "    std = X_test[\"Age\"].std()\n",
    "    is_null = dataset[\"Age\"].isna().sum()\n",
    "    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n",
    "    rand_age_series = pd.Series(rand_age, index=dataset[dataset[\"Age\"].isnull()].index)\n",
    "    dataset[\"Age\"].fillna(rand_age_series, inplace=True)\n",
    "    dataset[\"Age\"] = dataset[\"Age\"].astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T22:00:59.234414600Z",
     "start_time": "2024-02-25T22:00:59.149940Z"
    }
   },
   "id": "382104a86596fa97",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Feature Engineering the Deck Column \n",
    "#Cabins are mapped to a numerical Deck feature\n",
    "deck = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\n",
    "data = [X_train, X_test]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Cabin'] = dataset['Cabin'].fillna(\"U0\")\n",
    "    dataset['Deck'] = dataset['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n",
    "    dataset['Deck'] = dataset['Deck'].map(deck)\n",
    "    dataset['Deck'] = dataset['Deck'].fillna(0)\n",
    "    dataset['Deck'] = dataset['Deck'].astype(int)\n",
    "X_train = X_train.drop(['Cabin'], axis=1)\n",
    "X_test = X_test.drop(['Cabin'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T22:00:59.278747600Z",
     "start_time": "2024-02-25T22:00:59.158829400Z"
    }
   },
   "id": "e8ca56c07025d74e",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train[\"Embarked\"].describe()\n",
    "for dataset in [X_train, X_test]:\n",
    "    dataset[\"Embarked\"].fillna(\"S\", inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T22:00:59.278747600Z",
     "start_time": "2024-02-25T22:00:59.170588500Z"
    }
   },
   "id": "46c7b88f0da0a969",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T22:00:59.278747600Z",
     "start_time": "2024-02-25T22:00:59.175387900Z"
    }
   },
   "id": "32c820fc22b56a5d",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:Name: string, Ticket: string, Embarked: category",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m XGBClassifier(objective \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary:logistic\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env_de\\Lib\\site-packages\\xgboost\\core.py:620\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    618\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[0;32m    619\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[1;32m--> 620\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env_de\\Lib\\site-packages\\xgboost\\sklearn.py:1471\u001B[0m, in \u001B[0;36mXGBClassifier.fit\u001B[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001B[0m\n\u001B[0;32m   1460\u001B[0m     params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_class\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_\n\u001B[0;32m   1462\u001B[0m (\n\u001B[0;32m   1463\u001B[0m     model,\n\u001B[0;32m   1464\u001B[0m     metric,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1469\u001B[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001B[0;32m   1470\u001B[0m )\n\u001B[1;32m-> 1471\u001B[0m train_dmatrix, evals \u001B[38;5;241m=\u001B[39m _wrap_evaluation_matrices(\n\u001B[0;32m   1472\u001B[0m     missing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmissing,\n\u001B[0;32m   1473\u001B[0m     X\u001B[38;5;241m=\u001B[39mX,\n\u001B[0;32m   1474\u001B[0m     y\u001B[38;5;241m=\u001B[39my,\n\u001B[0;32m   1475\u001B[0m     group\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1476\u001B[0m     qid\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1477\u001B[0m     sample_weight\u001B[38;5;241m=\u001B[39msample_weight,\n\u001B[0;32m   1478\u001B[0m     base_margin\u001B[38;5;241m=\u001B[39mbase_margin,\n\u001B[0;32m   1479\u001B[0m     feature_weights\u001B[38;5;241m=\u001B[39mfeature_weights,\n\u001B[0;32m   1480\u001B[0m     eval_set\u001B[38;5;241m=\u001B[39meval_set,\n\u001B[0;32m   1481\u001B[0m     sample_weight_eval_set\u001B[38;5;241m=\u001B[39msample_weight_eval_set,\n\u001B[0;32m   1482\u001B[0m     base_margin_eval_set\u001B[38;5;241m=\u001B[39mbase_margin_eval_set,\n\u001B[0;32m   1483\u001B[0m     eval_group\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1484\u001B[0m     eval_qid\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1485\u001B[0m     create_dmatrix\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_dmatrix,\n\u001B[0;32m   1486\u001B[0m     enable_categorical\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menable_categorical,\n\u001B[0;32m   1487\u001B[0m     feature_types\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_types,\n\u001B[0;32m   1488\u001B[0m )\n\u001B[0;32m   1490\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster \u001B[38;5;241m=\u001B[39m train(\n\u001B[0;32m   1491\u001B[0m     params,\n\u001B[0;32m   1492\u001B[0m     train_dmatrix,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1501\u001B[0m     callbacks\u001B[38;5;241m=\u001B[39mcallbacks,\n\u001B[0;32m   1502\u001B[0m )\n\u001B[0;32m   1504\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobjective):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env_de\\Lib\\site-packages\\xgboost\\sklearn.py:448\u001B[0m, in \u001B[0;36m_wrap_evaluation_matrices\u001B[1;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001B[0m\n\u001B[0;32m    428\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_wrap_evaluation_matrices\u001B[39m(\n\u001B[0;32m    429\u001B[0m     missing: \u001B[38;5;28mfloat\u001B[39m,\n\u001B[0;32m    430\u001B[0m     X: Any,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    444\u001B[0m     feature_types: Optional[FeatureTypes],\n\u001B[0;32m    445\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Any, List[Tuple[Any, \u001B[38;5;28mstr\u001B[39m]]]:\n\u001B[0;32m    446\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001B[39;00m\n\u001B[0;32m    447\u001B[0m \u001B[38;5;124;03m    way.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 448\u001B[0m     train_dmatrix \u001B[38;5;241m=\u001B[39m create_dmatrix(\n\u001B[0;32m    449\u001B[0m         data\u001B[38;5;241m=\u001B[39mX,\n\u001B[0;32m    450\u001B[0m         label\u001B[38;5;241m=\u001B[39my,\n\u001B[0;32m    451\u001B[0m         group\u001B[38;5;241m=\u001B[39mgroup,\n\u001B[0;32m    452\u001B[0m         qid\u001B[38;5;241m=\u001B[39mqid,\n\u001B[0;32m    453\u001B[0m         weight\u001B[38;5;241m=\u001B[39msample_weight,\n\u001B[0;32m    454\u001B[0m         base_margin\u001B[38;5;241m=\u001B[39mbase_margin,\n\u001B[0;32m    455\u001B[0m         feature_weights\u001B[38;5;241m=\u001B[39mfeature_weights,\n\u001B[0;32m    456\u001B[0m         missing\u001B[38;5;241m=\u001B[39mmissing,\n\u001B[0;32m    457\u001B[0m         enable_categorical\u001B[38;5;241m=\u001B[39menable_categorical,\n\u001B[0;32m    458\u001B[0m         feature_types\u001B[38;5;241m=\u001B[39mfeature_types,\n\u001B[0;32m    459\u001B[0m         ref\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    460\u001B[0m     )\n\u001B[0;32m    462\u001B[0m     n_validation \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m eval_set \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(eval_set)\n\u001B[0;32m    464\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvalidate_or_none\u001B[39m(meta: Optional[Sequence], name: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Sequence:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env_de\\Lib\\site-packages\\xgboost\\sklearn.py:908\u001B[0m, in \u001B[0;36mXGBModel._create_dmatrix\u001B[1;34m(self, ref, **kwargs)\u001B[0m\n\u001B[0;32m    906\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:  \u001B[38;5;66;03m# `QuantileDMatrix` supports lesser types than DMatrix\u001B[39;00m\n\u001B[0;32m    907\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m--> 908\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DMatrix(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs, nthread\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env_de\\Lib\\site-packages\\xgboost\\core.py:620\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    618\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[0;32m    619\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[1;32m--> 620\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env_de\\Lib\\site-packages\\xgboost\\core.py:743\u001B[0m, in \u001B[0;36mDMatrix.__init__\u001B[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001B[0m\n\u001B[0;32m    740\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    741\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m--> 743\u001B[0m handle, feature_names, feature_types \u001B[38;5;241m=\u001B[39m dispatch_data_backend(\n\u001B[0;32m    744\u001B[0m     data,\n\u001B[0;32m    745\u001B[0m     missing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmissing,\n\u001B[0;32m    746\u001B[0m     threads\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnthread,\n\u001B[0;32m    747\u001B[0m     feature_names\u001B[38;5;241m=\u001B[39mfeature_names,\n\u001B[0;32m    748\u001B[0m     feature_types\u001B[38;5;241m=\u001B[39mfeature_types,\n\u001B[0;32m    749\u001B[0m     enable_categorical\u001B[38;5;241m=\u001B[39menable_categorical,\n\u001B[0;32m    750\u001B[0m )\n\u001B[0;32m    751\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m handle \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    752\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle \u001B[38;5;241m=\u001B[39m handle\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env_de\\Lib\\site-packages\\xgboost\\data.py:957\u001B[0m, in \u001B[0;36mdispatch_data_backend\u001B[1;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001B[0m\n\u001B[0;32m    955\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _from_tuple(data, missing, threads, feature_names, feature_types)\n\u001B[0;32m    956\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _is_pandas_df(data):\n\u001B[1;32m--> 957\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _from_pandas_df(data, enable_categorical, missing, threads,\n\u001B[0;32m    958\u001B[0m                            feature_names, feature_types)\n\u001B[0;32m    959\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _is_pandas_series(data):\n\u001B[0;32m    960\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _from_pandas_series(\n\u001B[0;32m    961\u001B[0m         data, missing, threads, enable_categorical, feature_names, feature_types\n\u001B[0;32m    962\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env_de\\Lib\\site-packages\\xgboost\\data.py:404\u001B[0m, in \u001B[0;36m_from_pandas_df\u001B[1;34m(data, enable_categorical, missing, nthread, feature_names, feature_types)\u001B[0m\n\u001B[0;32m    396\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_from_pandas_df\u001B[39m(\n\u001B[0;32m    397\u001B[0m     data: DataFrame,\n\u001B[0;32m    398\u001B[0m     enable_categorical: \u001B[38;5;28mbool\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    402\u001B[0m     feature_types: Optional[FeatureTypes],\n\u001B[0;32m    403\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DispatchedDataBackendReturnType:\n\u001B[1;32m--> 404\u001B[0m     data, feature_names, feature_types \u001B[38;5;241m=\u001B[39m _transform_pandas_df(\n\u001B[0;32m    405\u001B[0m         data, enable_categorical, feature_names, feature_types\n\u001B[0;32m    406\u001B[0m     )\n\u001B[0;32m    407\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env_de\\Lib\\site-packages\\xgboost\\data.py:378\u001B[0m, in \u001B[0;36m_transform_pandas_df\u001B[1;34m(data, enable_categorical, feature_names, feature_types, meta, meta_type)\u001B[0m\n\u001B[0;32m    366\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtypes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m    367\u001B[0m     is_sparse,\n\u001B[0;32m    368\u001B[0m     is_categorical_dtype,\n\u001B[0;32m    369\u001B[0m )\n\u001B[0;32m    371\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\n\u001B[0;32m    372\u001B[0m     dtype\u001B[38;5;241m.\u001B[39mname \u001B[38;5;129;01min\u001B[39;00m _pandas_dtype_mapper\n\u001B[0;32m    373\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m is_sparse(dtype)\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    376\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m dtype \u001B[38;5;129;01min\u001B[39;00m data\u001B[38;5;241m.\u001B[39mdtypes\n\u001B[0;32m    377\u001B[0m ):\n\u001B[1;32m--> 378\u001B[0m     _invalid_dataframe_dtype(data)\n\u001B[0;32m    380\u001B[0m feature_names, feature_types \u001B[38;5;241m=\u001B[39m _pandas_feature_info(\n\u001B[0;32m    381\u001B[0m     data, meta, feature_names, feature_types, enable_categorical\n\u001B[0;32m    382\u001B[0m )\n\u001B[0;32m    384\u001B[0m transformed \u001B[38;5;241m=\u001B[39m _pandas_cat_null(data)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env_de\\Lib\\site-packages\\xgboost\\data.py:270\u001B[0m, in \u001B[0;36m_invalid_dataframe_dtype\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m    268\u001B[0m type_err \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame.dtypes for data must be int, float, bool or category.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    269\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtype_err\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_ENABLE_CAT_ERR\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00merr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m--> 270\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n",
      "\u001B[1;31mValueError\u001B[0m: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:Name: string, Ticket: string, Embarked: category"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(objective = \"binary:logistic\")\n",
    "model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T22:01:00.356505600Z",
     "start_time": "2024-02-25T22:00:59.178899200Z"
    }
   },
   "id": "d84d0e3eb04fb1a4",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-25T22:01:00.344505400Z"
    }
   },
   "id": "b9bd22a2528c3470",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
